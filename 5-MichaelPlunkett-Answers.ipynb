{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "initial_id",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-05T22:00:41.820623Z",
          "start_time": "2024-02-05T22:00:41.761139Z"
        },
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import lucem_illud\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn\n",
        "import sklearn\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5dbb91751449d0ac",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "# Constants, Utility Functions, and Data Importing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a85842706707fe63",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-05T21:59:53.759464Z",
          "start_time": "2024-02-05T21:59:53.754361Z"
        },
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Constants\n",
        "LOW_NOISE = 0.2\n",
        "HIGH_NOISE = 0.45\n",
        "TEST_SPLIT = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d06bd1e4a8c2b26e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-05T22:12:00.043800Z",
          "start_time": "2024-02-05T22:12:00.005249Z"
        },
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Utility Functions\n",
        "def plotter(df: pd.DataFrame, category_key: str = \"category\"):\n",
        "    fig, ax = plt.subplots(figsize=(10, 10))\n",
        "    pallet = seaborn.color_palette(\n",
        "        palette=\"rainbow\", n_colors=len(set(df[category_key]))\n",
        "    )\n",
        "    for i, cat in enumerate(set(df[category_key])):\n",
        "        a = np.stack(df[df[category_key] == cat][\"vect\"])\n",
        "        ax.scatter(a[:, 0], a[:, 1], c=pallet[i], label=cat)\n",
        "    ax.legend(loc=\"center right\", title=\"Categories\")\n",
        "    ax.axis(\"off\")\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def pca_split_stats(\n",
        "    test_df: pd.DataFrame,\n",
        "    train_df: pd.DataFrame,\n",
        "    red_pca_key: str,\n",
        "    category_key: str = \"category\",\n",
        ") -> None:\n",
        "    logistic = sklearn.linear_model.LogisticRegression()\n",
        "    train_df[red_pca_key] = train_df[\"pca\"].apply(lambda x: x[:400])\n",
        "    test_df[red_pca_key] = test_df[\"pca\"].apply(lambda x: x[:400])\n",
        "\n",
        "    logistic.fit(np.stack(train_df[red_pca_key], axis=0), train_df[category_key])\n",
        "\n",
        "    print(\"Training:\")\n",
        "    print(\n",
        "        logistic.score(np.stack(train_df[red_pca_key], axis=0), train_df[category_key])\n",
        "    )\n",
        "    print(\"Testing:\")\n",
        "    print(logistic.score(np.stack(test_df[red_pca_key], axis=0), test_df[category_key]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "aff1aca6913b63a4",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-05T22:13:12.262364Z",
          "start_time": "2024-02-05T22:12:44.201850Z"
        },
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/michaelp/Documents/GitHub/computational-content-analysis/.venv/lib/python3.11/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
            "  warnings.warn(Warnings.W108)\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'tokenized_sentences'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m~/Documents/GitHub/computational-content-analysis/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[0;32mindex.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mindex.pyx:182\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'tokenized_sentences'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[10], line 14\u001b[0m\n\u001b[1;32m      8\u001b[0m     ucpd_reports \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/incident_dump.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m     ucpd_reports[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenized_text\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ucpd_reports[\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomments\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m     ]\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m     12\u001b[0m         lucem_illud\u001b[38;5;241m.\u001b[39mword_tokenize\n\u001b[1;32m     13\u001b[0m     )\n\u001b[0;32m---> 14\u001b[0m     ucpd_reports[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormalized_text\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mucpd_reports\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtokenized_sentences\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m     17\u001b[0m          lucem_illud\u001b[38;5;241m.\u001b[39mnormalizeTokens\n\u001b[1;32m     18\u001b[0m     )\n\u001b[1;32m     19\u001b[0m     ucpd_reports\u001b[38;5;241m.\u001b[39mto_feather(ucpd_feather_path)\n\u001b[1;32m     20\u001b[0m ucpd_reports\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\n",
            "File \u001b[0;32m~/Documents/GitHub/computational-content-analysis/.venv/lib/python3.11/site-packages/pandas/core/frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
            "File \u001b[0;32m~/Documents/GitHub/computational-content-analysis/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3805\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3806\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3807\u001b[0m     ):\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3809\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3811\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3812\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[0;31mKeyError\u001b[0m: 'tokenized_sentences'"
          ]
        }
      ],
      "source": [
        "# Data is sourced from a personal project of mine you can find here:\n",
        "# https://ucpd-incident-reporter-7cfdc3369124.herokuapp.com/\n",
        "ucpd_feather_path = \"data/fully_tokenized_ucpd_incidents.feather\"\n",
        "if os.path.isfile(ucpd_feather_path):\n",
        "    ucpd_reports = pd.read_feather(ucpd_feather_path)\n",
        "else:\n",
        "    # WARNING: This step takes about 120 minutes, so don't run it unless you need to.\n",
        "    ucpd_reports = pd.read_csv(\"data/incident_dump.csv\")\n",
        "    ucpd_reports[\"tokenized_text\"] = ucpd_reports[\"comments\"].apply(\n",
        "        lucem_illud.word_tokenize\n",
        "    )\n",
        "    ucpd_reports[\"normalized_text\"] = ucpd_reports[\"tokenized_sentences\"].apply(\n",
        "        lucem_illud.normalizeTokens\n",
        "    )\n",
        "    ucpd_reports.to_feather(ucpd_feather_path)\n",
        "ucpd_reports.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df8f5bc61d3bc989",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "## <font color=\"red\">*Exercise 1*</font>\n",
        "\n",
        "<font color=\"red\">Perform a content annotation survey of some kind in which at \n",
        "least 3 people evaluate and code each piece of content, using Amazon Mechanical \n",
        "Turk as described in the [MTurk slides on Canvas](https://canvas.uchicago.edu/courses/54694/files/folder/unfiled?preview=10675152), or by hand with friends.  \n",
        "With the resulting data, calculate, visualize and discuss inter-coder agreement or \n",
        "co-variation with appropriate metrics. What does this means for the reliability of \n",
        "human assessments regarding content in your domain?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "b28c30789992721a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-05T00:45:10.724873Z",
          "start_time": "2024-02-05T00:45:10.350705Z"
        },
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Figure out a way to chunk up the data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d4b7bd66b3e1bcf",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "## <font color=\"red\">*Exercise 2*</font>\n",
        "\n",
        "<font color=\"red\">Go back through all the cells above and generate 10 distinct \n",
        "artificial datasets and classify them with all the available methods. Add a cell \n",
        "immediately below and describe which classifier(s) worked best with which \n",
        "artificially constructed data source and why. Then go through all the empirical \n",
        "datasets (i.e., Newsgroups, Senate Small, Senate Large, Email Spam) and classify \n",
        "them with all available methods. Add a second cell immediately below and describe \n",
        "which classifier(s) worked best with which data set and why.\n",
        "\n",
        "<font color=\"red\">***Stretch*** (but also required) Wander through the SKLearn \n",
        "documentation available [here](http://scikit-learn.org/stable/), particularly \n",
        "perusing the classifiers. In cells following, identify and implement a new classifier \n",
        "that we have not yet used (e.g., AdaBoost, CART) on one artificial dataset and one real \n",
        "dataset (used above). Then, in the next cell describe the classifier, detail how it \n",
        "compares with the approaches above, and why it performed better or worse than others."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2aa34cf05a573b30",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "### Generated Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7e901d600e8261e",
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Dataset 1\n",
        "ln_random_df_train, ln_random_df_test = sklearn.model_selection.train_test_split(\n",
        "    lucem_illud.random(LOW_NOISE), test_size=TEST_SPLIT\n",
        ")\n",
        "# Dataset 2\n",
        "ln_and_split_df_train, ln_and_split_df_test = sklearn.model_selection.train_test_split(\n",
        "    lucem_illud.andSplit(LOW_NOISE), test_size=TEST_SPLIT\n",
        ")\n",
        "# Dataset 3\n",
        "ln_xor_split_df_train, ln_xor_split_df_test = sklearn.model_selection.train_test_split(\n",
        "    lucem_illud.xorSplit(LOW_NOISE), test_size=TEST_SPLIT\n",
        ")\n",
        "# Dataset 4\n",
        "(\n",
        "    ln_target_split_df_train,\n",
        "    ln_target_split_df_test,\n",
        ") = sklearn.model_selection.train_test_split(\n",
        "    lucem_illud.targetSplit(LOW_NOISE), test_size=TEST_SPLIT\n",
        ")\n",
        "# Dataset 5\n",
        "(\n",
        "    ln_multi_blobs_df_train,\n",
        "    ln_multi_blobs_df_test,\n",
        ") = sklearn.model_selection.train_test_split(\n",
        "    lucem_illud.multiBlobs(LOW_NOISE), test_size=TEST_SPLIT\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b381b692f6aa645d",
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Dataset 6\n",
        "hn_random_df_train, hn_random_df_test = sklearn.model_selection.train_test_split(\n",
        "    lucem_illud.random(HIGH_NOISE), test_size=TEST_SPLIT\n",
        ")\n",
        "# Dataset 7\n",
        "hn_and_split_df_train, hn_and_split_df_test = sklearn.model_selection.train_test_split(\n",
        "    lucem_illud.andSplit(HIGH_NOISE), test_size=TEST_SPLIT\n",
        ")\n",
        "# Dataset 8\n",
        "hn_xor_split_df_train, hn_xor_split_df_test = sklearn.model_selection.train_test_split(\n",
        "    lucem_illud.xorSplit(HIGH_NOISE), test_size=TEST_SPLIT\n",
        ")\n",
        "# Dataset 9\n",
        "(\n",
        "    hn_target_split_df_train,\n",
        "    hn_target_split_df_test,\n",
        ") = sklearn.model_selection.train_test_split(\n",
        "    lucem_illud.targetSplit(HIGH_NOISE), test_size=TEST_SPLIT\n",
        ")\n",
        "# Dataset 10\n",
        "(\n",
        "    hn_multi_blobs_df_train,\n",
        "    hn_multi_blobs_df_test,\n",
        ") = sklearn.model_selection.train_test_split(\n",
        "    lucem_illud.multiBlobs(HIGH_NOISE), test_size=TEST_SPLIT\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "152c060c87c7a1dd",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "### Empirical Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bcb71d4683afa8f",
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "7492cdac200a8ee4",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "## <font color=\"red\">*Exercise 3*</font>\n",
        "\n",
        "<font color=\"red\">In the cells immediately following, perform logistic regression \n",
        "classification using training, testing and un-coded (i.e., data you didn't code by \n",
        "hand but want to use your model on) data from texts and hand-classifications \n",
        "associated with your final project (e.g., these could be crowd-sourced codes \n",
        "gathered through Amazon Mechanical Turk in Exercise 1). Visualize the confusion \n",
        "matrix for training and testing sets. Calculate precision, recall, the F-measure, \n",
        "and AUC, then perform an ROC visualization. How do these classifiers perform? \n",
        "Extrapolate code from these models to all un-coded data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "6a9118ccc9481a85",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-05T00:45:10.724994Z",
          "start_time": "2024-02-05T00:45:10.354499Z"
        },
        "collapsed": false
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "97dc2de83ad6231f",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "## <font color=\"red\">*Exercise 4*</font>\n",
        "\n",
        "<font color=\"red\">In the cells immediately following, perform decision tree and \n",
        "random forest classification (binary, multinomial or continuous) using training, \n",
        "testing and extrapolation (un-coded) data from texts and hand-classifications \n",
        "associated with your final project. As with ***Exercise 2***, these could be \n",
        "crowdsourced codes gathered through Amazon Mechanical Turk last week. Visualize \n",
        "the classification of data points. Calculate relevant metrics (e.g., precision, \n",
        "recall, the F-measure, and AUC). Now build an ensemble classifier by bagging trees \n",
        "into a random forest. Visualize the result. How do these classifiers perform? \n",
        "What does ensemble learning do?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "be2e65f945decf2c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-05T00:45:10.732368Z",
          "start_time": "2024-02-05T00:45:10.356217Z"
        },
        "collapsed": false
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "7b459f9a4f8cef61",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "## <font color=\"red\">*Exercise 6*</font>\n",
        "\n",
        "<font color=\"red\">In the cells immediately following, perform a neural network \n",
        "classification and calculate relevant metrics (e.g., precision, recall, the \n",
        "F-measure, and AUC). How does this classify relevant to *k*-nearest neighbor, \n",
        "logistic and decision-tree approaches?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "af75b7d8174467e2",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-05T00:45:10.732458Z",
          "start_time": "2024-02-05T00:45:10.358328Z"
        },
        "collapsed": false
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "d2796a48dd01a6f9",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "## <font color=\"red\">*Exercise 7*</font>\n",
        "\n",
        "<font color=\"red\">In the cells immediately following, use the pipeline functions \n",
        "or the word or sentence vector functions (e.g., similarity) to explore the social \n",
        "game underlying the production and meaning of texts associated with your final project. \n",
        "How does BERT help you gain insight regarding your research question that is similar \n",
        "and different from prior methods?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "98b1f3a988c7ca24",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-05T00:45:10.732505Z",
          "start_time": "2024-02-05T00:45:10.360204Z"
        },
        "collapsed": false
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f83e88d8954fa9eb",
      "metadata": {
        "collapsed": false
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
