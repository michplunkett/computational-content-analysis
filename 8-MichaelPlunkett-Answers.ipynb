{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "initial_id",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-26T20:10:52.806779Z",
          "start_time": "2024-02-26T20:10:50.179438Z"
        },
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts.chat import (\n",
        "    AIMessagePromptTemplate,\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "baca9619066ac3df",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "**Note:** Worked with Chanteria Milner on this assignment.\n",
        "\n",
        "<img src=\"misc/syllabus_segment.png\" style=\"width:400px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cc1aa3b4deec182",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "# Constants, Utility Functions, and Data Importing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "20ef1a145a95feae",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-26T20:10:52.939397Z",
          "start_time": "2024-02-26T20:10:52.806676Z"
        },
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING! api_key is not default parameter.\n",
            "                    api_key was transferred to model_kwargs.\n",
            "                    Please confirm that api_key is what you intended.\n"
          ]
        }
      ],
      "source": [
        "# Constants and clients\n",
        "GPT_MODEL = \"gpt-3.5-turbo\"\n",
        "MAX_CHAR_LEN = 5000000\n",
        "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "openai_client = OpenAI(api_key=OPENAI_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2cbc9341a70ed576",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-26T20:10:52.949943Z",
          "start_time": "2024-02-26T20:10:52.946335Z"
        },
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Utility functions\n",
        "\n",
        "\n",
        "def kl_divergence(x, y):\n",
        "    P = x.copy()\n",
        "    Q = y.copy()\n",
        "    P.columns = [\"P\"]\n",
        "    Q.columns = [\"Q\"]\n",
        "    df = Q.join(P).fillna(0)\n",
        "    p = df.iloc[:, 1]\n",
        "    q = df.iloc[:, 0]\n",
        "    D_kl = scipy.stats.entropy(p, q)\n",
        "    return D_kl\n",
        "\n",
        "\n",
        "def chi2_divergence(x, y):\n",
        "    P = x.copy()\n",
        "    Q = y.copy()\n",
        "    P.columns = [\"P\"]\n",
        "    Q.columns = [\"Q\"]\n",
        "    df = Q.join(P).fillna(0)\n",
        "    p = df.iloc[:, 1]\n",
        "    q = df.iloc[:, 0]\n",
        "    return scipy.stats.chisquare(p, q).statistic\n",
        "\n",
        "\n",
        "def corpus_divergence(corpus1, corpus2, difference=\"KL\"):\n",
        "    \"\"\"Difference parameter can equal KL, Chi2, or Wass\"\"\"\n",
        "    freqP = nltk.FreqDist(corpus1)\n",
        "    P = pd.DataFrame(\n",
        "        list(freqP.values()), columns=[\"frequency\"], index=list(freqP.keys())\n",
        "    )\n",
        "    freqQ = nltk.FreqDist(corpus2)\n",
        "    Q = pd.DataFrame(\n",
        "        list(freqQ.values()), columns=[\"frequency\"], index=list(freqQ.keys())\n",
        "    )\n",
        "    if difference == \"KL\":\n",
        "        return kl_divergence(P, Q)\n",
        "    elif difference == \"Chi2\":\n",
        "        return chi2_divergence(P, Q)\n",
        "    elif difference == \"KS\":\n",
        "        try:\n",
        "            return scipy.stats.ks_2samp(P[\"frequency\"], Q[\"frequency\"]).statistic\n",
        "        except:\n",
        "            return scipy.stats.ks_2samp(P[\"frequency\"], Q[\"frequency\"])\n",
        "    elif difference == \"Wasserstein\":\n",
        "        try:\n",
        "            return scipy.stats.wasserstein_distance(\n",
        "                P[\"frequency\"], Q[\"frequency\"], u_weights=None, v_weights=None\n",
        "            ).statistic\n",
        "        except:\n",
        "            return scipy.stats.wasserstein_distance(\n",
        "                P[\"frequency\"], Q[\"frequency\"], u_weights=None, v_weights=None\n",
        "            )\n",
        "\n",
        "\n",
        "def get_density(df):\n",
        "    data = df\n",
        "    density = scipy.stats.gaussian_kde(data)\n",
        "    width = np.max(data) - np.min(data)\n",
        "    xs = np.linspace(np.min(data) - width / 5, np.max(data) + width / 5, 600)\n",
        "    density.covariance_factor = lambda: 0.25\n",
        "    density._compute_covariance()\n",
        "    return xs, density(xs)\n",
        "\n",
        "\n",
        "def draw_network(df, title):\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    G = nx.DiGraph()\n",
        "    for from_ in df.index:\n",
        "        for to_ in df.columns:\n",
        "            G.add_edge(from_, to_, weight=df.loc[from_][to_])\n",
        "\n",
        "    pos = nx.spring_layout(G, k=0.55, iterations=20)\n",
        "    edges, weights = zip(*nx.get_edge_attributes(G, \"weight\").items())\n",
        "    weights = np.array(weights)\n",
        "    # weights = weights*weights\n",
        "    weights = 6 * weights / np.max(weights)\n",
        "    print(title)\n",
        "\n",
        "    edge_colors = 20 * (weights / np.max(weights))\n",
        "    edge_colors = edge_colors.astype(int)\n",
        "    #     nx.draw_networkx_nodes(G,pos,node_size=1200,alpha=0.7,node_color='#99cef7')\n",
        "    #     nx.draw_networkx_edges(G,pos,edge_color=edge_colors)\n",
        "    #     nx.draw_networkx_labels(G,pos,font_weight='bold')\n",
        "    nx.draw(\n",
        "        G,\n",
        "        pos,\n",
        "        with_labels=True,\n",
        "        font_weight=\"bold\",\n",
        "        width=weights,\n",
        "        edge_color=255 - edge_colors,\n",
        "        node_color=\"#99cef7\",\n",
        "        node_size=1200,\n",
        "        alpha=0.75,\n",
        "        arrows=True,\n",
        "        arrowsize=20,\n",
        "    )\n",
        "    return edge_colors\n",
        "\n",
        "\n",
        "def create_system_message_prompt():\n",
        "    \"\"\"Creates a system message prompt\"\"\"\n",
        "    personality_template = \"\"\"\n",
        "    The following is a conversation with an AI assistant.\n",
        "    \"\"\"\n",
        "    return SystemMessagePromptTemplate.from_template(personality_template)\n",
        "\n",
        "\n",
        "def create_chat_prompt(human_history, ai_history):\n",
        "    \"\"\"Creates a chat prompt template with human history, and AI history.\"\"\"\n",
        "    messages = []\n",
        "    create_system_message_prompt()\n",
        "\n",
        "    for h, a in zip(human_history, ai_history):\n",
        "        messages.append(HumanMessagePromptTemplate.from_template(h))\n",
        "        messages.append(AIMessagePromptTemplate.from_template(a))\n",
        "\n",
        "    messages.append(HumanMessagePromptTemplate.from_template(\"{input}\"))\n",
        "    return ChatPromptTemplate.from_messages(messages)\n",
        "\n",
        "\n",
        "def query_chain(chain, input_text):\n",
        "    \"\"\"Queries the conversation chain with the given input.\"\"\"\n",
        "    return chain.run(input_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ea9f4f4a6704a9d6",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-26T20:10:53.152651Z",
          "start_time": "2024-02-26T20:10:52.948432Z"
        },
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>case_url</th>\n      <th>author</th>\n      <th>author_url</th>\n      <th>description</th>\n      <th>pdf_url</th>\n      <th>raw_text</th>\n      <th>cleaned_text</th>\n      <th>tokenized_text_sents</th>\n      <th>tokenized_text_words</th>\n      <th>tokenized_text_words_norm</th>\n      <th>text_pos</th>\n      <th>text_pos_tags_of_interest</th>\n      <th>joined_text_pos_tags_of_interest</th>\n      <th>knn_clusters</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Dobbs v. Jackson Women's Health Organization</td>\n      <td>https://supreme.justia.com/cases/federal/us/59...</td>\n      <td>Samuel A. Alito, Jr.</td>\n      <td>https://supreme.justia.com/justices/samuel-a-a...</td>\n      <td>The Constitution does not confer a right to ab...</td>\n      <td>https://supreme.justia.com/cases/federal/us/59...</td>\n      <td>\\n \\n \\n  \\n    \\n       \\n \\n  \\n \\n \\n \\n ...</td>\n      <td>1 (Slip Opinion) OCTOBER TERM, 2021 Syllabus N...</td>\n      <td>[1 (slip opinion) october term, 2021 syllabus ...</td>\n      <td>[slip, opinion, october, term, syllabus, note,...</td>\n      <td>[slip, opinion, october, term, syllabus, note,...</td>\n      <td>[[1, X], [(, PUNCT], [Slip, PROPN], [Opinion, ...</td>\n      <td>[feasible, syllabus, headnote, released, done,...</td>\n      <td>feasible syllabus headnote released done conne...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Whole Woman's Health v. Hellerstedt</td>\n      <td>https://supreme.justia.com/cases/federal/us/57...</td>\n      <td>Stephen Breyer</td>\n      <td>https://supreme.justia.com/justices/stephen-br...</td>\n      <td>Two restrictions imposed by a Texas abortion l...</td>\n      <td>https://supreme.justia.com/cases/federal/us/57...</td>\n      <td>\\n \\n \\n  \\n    \\n  \\n \\n  \\n \\n  \\n \\n \\n \\...</td>\n      <td>1 (Slip Opinion) OCTOBER TERM, 2015 Syllabus N...</td>\n      <td>[1 (slip opinion) october term, 2015 syllabus ...</td>\n      <td>[slip, opinion, october, term, syllabus, note,...</td>\n      <td>[slip, opinion, october, term, syllabus, note,...</td>\n      <td>[[1, X], [(, PUNCT], [Slip, PROPN], [Opinion, ...</td>\n      <td>[feasible, syllabus, headnote, released, done,...</td>\n      <td>feasible syllabus headnote released done conne...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Gonzales v. Carhart</td>\n      <td>https://supreme.justia.com/cases/federal/us/55...</td>\n      <td>Anthony Kennedy</td>\n      <td>https://supreme.justia.com/justices/anthony-ke...</td>\n      <td>When it has a rational basis to act, and it do...</td>\n      <td>https://supreme.justia.com/cases/federal/us/55...</td>\n      <td>(Bench Opinion)  OCTOBER TERM, 2006 1 \\n \\nSyl...</td>\n      <td>(Bench Opinion) OCTOBER TERM, 2006 1 Syllabus ...</td>\n      <td>[(bench opinion) october term, 2006 1 syllabus...</td>\n      <td>[bench, opinion, october, term, syllabus, note...</td>\n      <td>[bench, opinion, october, term, syllabus, note...</td>\n      <td>[[(, PUNCT], [Bench, PROPN], [Opinion, PROPN],...</td>\n      <td>[NOTE, feasible, syllabus, headnote, released,...</td>\n      <td>NOTE feasible syllabus headnote released done ...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Stenberg v. Carhart</td>\n      <td>https://supreme.justia.com/cases/federal/us/53...</td>\n      <td>Stephen Breyer</td>\n      <td>https://supreme.justia.com/justices/stephen-br...</td>\n      <td>A state law criminalizing the performance of p...</td>\n      <td>https://supreme.justia.com/cases/federal/us/53...</td>\n      <td>530US2 Unit: $U85 [11-21-01 16:51:50] PAGES PG...</td>\n      <td>530US2 Unit: U85 [11-21-01 16:51:50] PAGES PGT...</td>\n      <td>[530us2 unit: u85, [11-21-01 16:51:50] pages p...</td>\n      <td>[530us2, unit, u85, 16:51:50, pages, pgt, o, p...</td>\n      <td>[530us2, unit, u85, 16:51:50, page, pgt, o, pi...</td>\n      <td>[[530US2, NUM], [Unit, NOUN], [:, PUNCT], [U85...</td>\n      <td>[Unit, STEN, eighth, circuit, Argued, offers, ...</td>\n      <td>Unit STEN eighth circuit Argued offers basic p...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Planned Parenthood of Southeastern Pennsylvani...</td>\n      <td>https://supreme.justia.com/cases/federal/us/50...</td>\n      <td>Anthony Kennedy</td>\n      <td>https://supreme.justia.com/justices/anthony-ke...</td>\n      <td>An undue burden exists, and therefore a provis...</td>\n      <td>https://supreme.justia.com/cases/federal/us/50...</td>\n      <td>505us3u117 07-09-96 09:34:02 PAGES OPINPGT\\n83...</td>\n      <td>505us3u117 07-09-96 09:34:02 PAGES OPINPGT 833...</td>\n      <td>[505us3u117 07-09-96 09:34:02 pages opinpgt 83...</td>\n      <td>[505us3u117, 09:34:02, pages, opinpgt, october...</td>\n      <td>[505us3u117, 09:34:02, page, opinpgt, october,...</td>\n      <td>[[505us3u117, NUM], [07, NUM], [-, PUNCT], [09...</td>\n      <td>[PLANNED, PARENTHOOD, appeals, third, circuit,...</td>\n      <td>PLANNED PARENTHOOD appeals third circuit No Ar...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "                                               title  \\\n0       Dobbs v. Jackson Women's Health Organization   \n1                Whole Woman's Health v. Hellerstedt   \n2                                Gonzales v. Carhart   \n3                                Stenberg v. Carhart   \n4  Planned Parenthood of Southeastern Pennsylvani...   \n\n                                            case_url                author  \\\n0  https://supreme.justia.com/cases/federal/us/59...  Samuel A. Alito, Jr.   \n1  https://supreme.justia.com/cases/federal/us/57...        Stephen Breyer   \n2  https://supreme.justia.com/cases/federal/us/55...       Anthony Kennedy   \n3  https://supreme.justia.com/cases/federal/us/53...        Stephen Breyer   \n4  https://supreme.justia.com/cases/federal/us/50...       Anthony Kennedy   \n\n                                          author_url  \\\n0  https://supreme.justia.com/justices/samuel-a-a...   \n1  https://supreme.justia.com/justices/stephen-br...   \n2  https://supreme.justia.com/justices/anthony-ke...   \n3  https://supreme.justia.com/justices/stephen-br...   \n4  https://supreme.justia.com/justices/anthony-ke...   \n\n                                         description  \\\n0  The Constitution does not confer a right to ab...   \n1  Two restrictions imposed by a Texas abortion l...   \n2  When it has a rational basis to act, and it do...   \n3  A state law criminalizing the performance of p...   \n4  An undue burden exists, and therefore a provis...   \n\n                                             pdf_url  \\\n0  https://supreme.justia.com/cases/federal/us/59...   \n1  https://supreme.justia.com/cases/federal/us/57...   \n2  https://supreme.justia.com/cases/federal/us/55...   \n3  https://supreme.justia.com/cases/federal/us/53...   \n4  https://supreme.justia.com/cases/federal/us/50...   \n\n                                            raw_text  \\\n0    \\n \\n \\n  \\n    \\n       \\n \\n  \\n \\n \\n \\n ...   \n1    \\n \\n \\n  \\n    \\n  \\n \\n  \\n \\n  \\n \\n \\n \\...   \n2  (Bench Opinion)  OCTOBER TERM, 2006 1 \\n \\nSyl...   \n3  530US2 Unit: $U85 [11-21-01 16:51:50] PAGES PG...   \n4  505us3u117 07-09-96 09:34:02 PAGES OPINPGT\\n83...   \n\n                                        cleaned_text  \\\n0  1 (Slip Opinion) OCTOBER TERM, 2021 Syllabus N...   \n1  1 (Slip Opinion) OCTOBER TERM, 2015 Syllabus N...   \n2  (Bench Opinion) OCTOBER TERM, 2006 1 Syllabus ...   \n3  530US2 Unit: U85 [11-21-01 16:51:50] PAGES PGT...   \n4  505us3u117 07-09-96 09:34:02 PAGES OPINPGT 833...   \n\n                                tokenized_text_sents  \\\n0  [1 (slip opinion) october term, 2021 syllabus ...   \n1  [1 (slip opinion) october term, 2015 syllabus ...   \n2  [(bench opinion) october term, 2006 1 syllabus...   \n3  [530us2 unit: u85, [11-21-01 16:51:50] pages p...   \n4  [505us3u117 07-09-96 09:34:02 pages opinpgt 83...   \n\n                                tokenized_text_words  \\\n0  [slip, opinion, october, term, syllabus, note,...   \n1  [slip, opinion, october, term, syllabus, note,...   \n2  [bench, opinion, october, term, syllabus, note...   \n3  [530us2, unit, u85, 16:51:50, pages, pgt, o, p...   \n4  [505us3u117, 09:34:02, pages, opinpgt, october...   \n\n                           tokenized_text_words_norm  \\\n0  [slip, opinion, october, term, syllabus, note,...   \n1  [slip, opinion, october, term, syllabus, note,...   \n2  [bench, opinion, october, term, syllabus, note...   \n3  [530us2, unit, u85, 16:51:50, page, pgt, o, pi...   \n4  [505us3u117, 09:34:02, page, opinpgt, october,...   \n\n                                            text_pos  \\\n0  [[1, X], [(, PUNCT], [Slip, PROPN], [Opinion, ...   \n1  [[1, X], [(, PUNCT], [Slip, PROPN], [Opinion, ...   \n2  [[(, PUNCT], [Bench, PROPN], [Opinion, PROPN],...   \n3  [[530US2, NUM], [Unit, NOUN], [:, PUNCT], [U85...   \n4  [[505us3u117, NUM], [07, NUM], [-, PUNCT], [09...   \n\n                           text_pos_tags_of_interest  \\\n0  [feasible, syllabus, headnote, released, done,...   \n1  [feasible, syllabus, headnote, released, done,...   \n2  [NOTE, feasible, syllabus, headnote, released,...   \n3  [Unit, STEN, eighth, circuit, Argued, offers, ...   \n4  [PLANNED, PARENTHOOD, appeals, third, circuit,...   \n\n                    joined_text_pos_tags_of_interest  knn_clusters  \n0  feasible syllabus headnote released done conne...             0  \n1  feasible syllabus headnote released done conne...             0  \n2  NOTE feasible syllabus headnote released done ...             5  \n3  Unit STEN eighth circuit Argued offers basic p...             5  \n4  PLANNED PARENTHOOD appeals third circuit No Ar...             0  "
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Data importing\n",
        "scotus_df = pd.read_feather(\"data/scotus_cases_clustered.fea\")\n",
        "scotus_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d64bc92c9f05ea22",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "## <font color=\"red\">*Exercise 1*</font>\n",
        "\n",
        "<font color=\"red\">Construct cells immediately below this that use ConvoKit to analyze a Corpus other \n",
        "than 'subreddit-Cornell', including at least one function you find in the package \n",
        "not used above. You can also generate a ConvoKit Corpus from your own dataset based \n",
        "on [their Corpus from .txt files tutorial](https://github.com/CornellNLP/Cornell-Conversational-Analysis-Toolkit/blob/master/examples/converting_movie_corpus.ipynb) or [their Corpus from pandas tutorial](https://github.com/CornellNLP/Cornell-Conversational-Analysis-Toolkit/blob/master/examples/corpus_from_pandas.ipynb), but that may \n",
        "be time-consuming for a weekly assignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db52d201f66fc01b",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-25T22:11:17.590522Z",
          "start_time": "2024-02-25T22:11:17.585897Z"
        },
        "collapsed": false
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "908dc21f632ad37e",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "## <font color=\"red\">*Exercise 2*</font>\n",
        "\n",
        "<font color=\"red\">Construct cells immediately below this that perform a similar social \n",
        "similarity or influence analysis on a dataset relevant to your final project (__or \n",
        "one from ConvoKit__). Create relationships between actors in a network based on your \n",
        "dataset (e.g., person to person or document to document), and perform analyses that \n",
        "interrogate the structure of their interactions, similarity, and/or influence on \n",
        "one another. (For example, if relevant to your final project, you could explore \n",
        "different soap operas, counting how many times a character may have used the word \n",
        "love in conversation with another character, and identify if characters in love \n",
        "speak like each other. Or do opposites attract?) What does that analysis and its \n",
        "output reveal about the relative influence of each actor on others? What does it \n",
        "reveal about the social game being played?\n",
        "\n",
        "<font color=\"red\">Stretch 1:\n",
        "Render the social network with weights (e.g., based on the number of scenes in \n",
        "which actors appear together), then calculate the most central actors in the \n",
        "`show.Realtime` output can be viewed in shell.\n",
        "\n",
        "<font color=\"red\">Stretch 2:\n",
        "Implement more complex measures of similarity based on the papers you have read."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c0d9307c9a390ff",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-25T22:11:17.590825Z",
          "start_time": "2024-02-25T22:11:17.589715Z"
        },
        "collapsed": false
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "670ab4047643c5a7",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "## <font color=\"red\">*Exercise 3*</font>\n",
        "\n",
        "<font color=\"red\">Review the documentation for tools and agents from LangChain. Use at \n",
        "least two tools with appropriate agents discovered during your review to construct a \n",
        "chain addressing questions pertinent to your final project. If your project dataset \n",
        "is unsuitable for this task, select an alternative small-sized dataset for \n",
        "implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79f2959169df6d40",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-25T22:11:17.751124Z",
          "start_time": "2024-02-25T22:11:17.732118Z"
        },
        "collapsed": false
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "ff78f725cfb57da5",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "## <font color=\"red\">*Exercise 4*</font>\n",
        "\n",
        "<font color=\"red\">Use LangChain(you're welcome to not use it) to set up conversations with LLM \n",
        "agents for questions related to your final project (if relevant), or think of a \n",
        "scenario that a simulated conversation could be useful to answer a research question \n",
        "and find a dataset to implement it. What does it reveal about the social game involved \n",
        "with your dataset?\n",
        "\n",
        "<font color=\"red\"> Stretch: Use the idea of memory retrieval(or other methods) to design better \n",
        "templates for the LLM conversation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79893be96979326",
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
