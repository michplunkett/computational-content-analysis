{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "41272f2bbf30eba2",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-21T04:37:21.030164Z",
          "start_time": "2024-02-21T04:37:17.615628Z"
        },
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "import pandas as pd\n",
        "import requests\n",
        "import statsmodels.api as sm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8a598f88767a547",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "## <font color=\"red\">*Exercise 1*</font>\n",
        "\n",
        "<font color=\"red\">Describe 2 separate predictions relevant to your project and associated texts, which involve predicting text that has not been observed based on patterns that have. Then, in a single, short paragraph, describe a research design through which you could use textual features and the tools of classification and regression to evaluate these predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "5feba27093e48da5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T20:54:55.935375Z",
          "start_time": "2024-02-13T20:54:55.923724Z"
        },
        "collapsed": false
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "c592b29cb697aca",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "## <font color=\"red\">*Exercise 2*</font>\n",
        "\n",
        "<font color=\"red\">Propose a simple causal model in your data, or a different causal model in the annotated Internet Arguments Corpus (e.g., a different treatment, a different outcome), and test it using a linear or logistic regression model. If you are using social media data for your final project, we encourage you to classify or annotate a sample of that data (either computationally or with human annotators) and examine the effect of texts on replies to that text (e.g., Reddit posts on Reddit comments, Tweets on Twitter replies, YouTube video transcripts on YouTube comments or ratings). You do not need to make a graph of the causal model, but please make it clear (e.g., \"X affects Y, and C affects both X and Y.\").\n",
        "    \n",
        "<font color=\"red\">Also consider using the [ConvoKit datasets](https://convokit.cornell.edu/documentation/datasets.html)! Anytime there is conversation, there is an opportunity to explore the effects of early parts of the conversation on later parts. We will explore this further in Week 8 on Text Generation and Conversation.\n",
        "    \n",
        "<font color=\"red\">***Stretch*** (not required): Propose a more robust identification strategy using either matching, difference in difference, regression discontinuity, or an instrumental variable. Each of these methods usually gives you a more precise identification of the causal effect than a unconditional regression. Scott Cunningham's [Causal Inference: The Mixtape](https://mixtape.scunning.com/) is a free textbook on these topics, and all have good YouTube video explanations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "66b724f722d18b2a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-21T04:26:43.219532Z",
          "start_time": "2024-02-21T04:22:11.687814Z"
        },
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloaded file: http://nldslab.soe.ucsc.edu/iac/iac_v1.1.zip\n"
          ]
        }
      ],
      "source": [
        "# This takes about 5 minutes to execute\n",
        "# The `https` link does not work, so there's no need to change it\n",
        "url = \"http://nldslab.soe.ucsc.edu/iac/iac_v1.1.zip\"\n",
        "\n",
        "req = requests.get(url)\n",
        "\n",
        "filename = url.split(\"/\")[-1]\n",
        "with open(filename, \"wb\") as output_file:\n",
        "    output_file.write(req.content)\n",
        "print(\"Downloaded file: \" + url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "beadb7a3106da2d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-21T04:30:48.394790Z",
          "start_time": "2024-02-21T04:30:48.164569Z"
        },
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Zip to DataFrame\n",
        "with zipfile.ZipFile(\"iac_v1.1.zip\") as z:\n",
        "    with z.open(\n",
        "        \"iac_v1.1/data/fourforums/annotations/mechanical_turk/qr_averages.csv\"\n",
        "    ) as f:\n",
        "        qr = pd.read_csv(f)\n",
        "\n",
        "    with z.open(\n",
        "        \"iac_v1.1/data/fourforums/annotations/mechanical_turk/qr_meta.csv\"\n",
        "    ) as f:\n",
        "        md = pd.read_csv(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "fee62c2be977e19e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-21T04:35:36.571795Z",
          "start_time": "2024-02-21T04:35:36.539819Z"
        },
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>quote</th>\n      <th>response1</th>\n      <th>response2</th>\n      <th>attack_r1</th>\n      <th>fact-feeling_r1</th>\n      <th>nicenasty_r1</th>\n      <th>sarcasm_r1</th>\n      <th>agreement_r2</th>\n      <th>key_r1</th>\n      <th>discussion_id_x_r1</th>\n      <th>...</th>\n      <th>questioning-asserting_unsure_r2</th>\n      <th>sarcasm_r2</th>\n      <th>sarcasm_unsure_r2</th>\n      <th>discussion_id_y_r2</th>\n      <th>response_post_id_r2</th>\n      <th>quote_post_id_r2</th>\n      <th>term_r2</th>\n      <th>task1 num annot_r2</th>\n      <th>task2 num annot_r2</th>\n      <th>task2 num disagree_r2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I remember looking at the classic evolutionary...</td>\n      <td>Why do you find it necessary to fit observatio...</td>\n      <td>Evolution has no goals, it is merely a beautif...</td>\n      <td>0.333333</td>\n      <td>0.333333</td>\n      <td>0.666667</td>\n      <td>0.200000</td>\n      <td>-2.833333</td>\n      <td>(731, 1)</td>\n      <td>6032</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.166667</td>\n      <td>6032</td>\n      <td>149673</td>\n      <td>149609.0</td>\n      <td>None</td>\n      <td>6</td>\n      <td>5</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>What is the fun in that?</td>\n      <td>Seriously? Well, I come here hoping for someth...</td>\n      <td>nah, I was just poking fun because I can! Pers...</td>\n      <td>-0.600000</td>\n      <td>-2.200000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-2.166667</td>\n      <td>(697, 2)</td>\n      <td>5205</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.2</td>\n      <td>0.166667</td>\n      <td>5205</td>\n      <td>123129</td>\n      <td>122800.0</td>\n      <td>None</td>\n      <td>6</td>\n      <td>5</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>First off, the scientific method goes:\\n \\n 1)...</td>\n      <td>You guys know me. Always happy to correct anyo...</td>\n      <td>Ah, thanks for the correction, although there ...</td>\n      <td>2.400000</td>\n      <td>2.800000</td>\n      <td>2.200000</td>\n      <td>0.000000</td>\n      <td>-0.400000</td>\n      <td>(9, 0)</td>\n      <td>9449</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>0.400000</td>\n      <td>9449</td>\n      <td>247243</td>\n      <td>247240.0</td>\n      <td>No terms in first 10</td>\n      <td>5</td>\n      <td>7</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>You can ignore the obvious question. This is w...</td>\n      <td>Actually what they are really doing is ignorin...</td>\n      <td>Really, then show me how I'm wrong - without d...</td>\n      <td>-3.500000</td>\n      <td>-3.166667</td>\n      <td>-3.166667</td>\n      <td>0.166667</td>\n      <td>-1.833333</td>\n      <td>(1077, 1)</td>\n      <td>3467</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.2</td>\n      <td>0.166667</td>\n      <td>3467</td>\n      <td>73783</td>\n      <td>73741.0</td>\n      <td>really</td>\n      <td>6</td>\n      <td>5</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Its really sad what these gay predator priests...</td>\n      <td>Homosexuals are attracted to adults of the sam...</td>\n      <td>Homosexuals are attracted to people of the sam...</td>\n      <td>0.166667</td>\n      <td>2.166667</td>\n      <td>-0.166667</td>\n      <td>0.400000</td>\n      <td>-2.666667</td>\n      <td>(611, 0)</td>\n      <td>4337</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>4337</td>\n      <td>112012</td>\n      <td>112008.0</td>\n      <td>No terms in first 10</td>\n      <td>6</td>\n      <td>7</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows \u00d7 59 columns</p>\n</div>",
            "text/plain": "                                               quote  \\\n0  I remember looking at the classic evolutionary...   \n1                           What is the fun in that?   \n2  First off, the scientific method goes:\\n \\n 1)...   \n3  You can ignore the obvious question. This is w...   \n4  Its really sad what these gay predator priests...   \n\n                                           response1  \\\n0  Why do you find it necessary to fit observatio...   \n1  Seriously? Well, I come here hoping for someth...   \n2  You guys know me. Always happy to correct anyo...   \n3  Actually what they are really doing is ignorin...   \n4  Homosexuals are attracted to adults of the sam...   \n\n                                           response2  attack_r1  \\\n0  Evolution has no goals, it is merely a beautif...   0.333333   \n1  nah, I was just poking fun because I can! Pers...  -0.600000   \n2  Ah, thanks for the correction, although there ...   2.400000   \n3  Really, then show me how I'm wrong - without d...  -3.500000   \n4  Homosexuals are attracted to people of the sam...   0.166667   \n\n   fact-feeling_r1  nicenasty_r1  sarcasm_r1  agreement_r2     key_r1  \\\n0         0.333333      0.666667    0.200000     -2.833333   (731, 1)   \n1        -2.200000      0.000000    0.000000     -2.166667   (697, 2)   \n2         2.800000      2.200000    0.000000     -0.400000     (9, 0)   \n3        -3.166667     -3.166667    0.166667     -1.833333  (1077, 1)   \n4         2.166667     -0.166667    0.400000     -2.666667   (611, 0)   \n\n   discussion_id_x_r1  ...  questioning-asserting_unsure_r2  sarcasm_r2  \\\n0                6032  ...                              0.0         0.0   \n1                5205  ...                              0.0         0.2   \n2                9449  ...                              NaN         0.0   \n3                3467  ...                              0.0         0.2   \n4                4337  ...                              0.0         0.0   \n\n   sarcasm_unsure_r2  discussion_id_y_r2  response_post_id_r2  \\\n0           0.166667                6032               149673   \n1           0.166667                5205               123129   \n2           0.400000                9449               247243   \n3           0.166667                3467                73783   \n4           0.000000                4337               112012   \n\n   quote_post_id_r2               term_r2  task1 num annot_r2  \\\n0          149609.0                  None                   6   \n1          122800.0                  None                   6   \n2          247240.0  No terms in first 10                   5   \n3           73741.0                really                   6   \n4          112008.0  No terms in first 10                   6   \n\n   task2 num annot_r2  task2 num disagree_r2  \n0                   5                      2  \n1                   5                      2  \n2                   7                      0  \n3                   5                      2  \n4                   7                      4  \n\n[5 rows x 59 columns]"
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Creating the DataFrame that we'll use for the causal test\n",
        "pairs = qr.merge(md, how=\"inner\", on=\"key\")\n",
        "pairs = pairs[~pairs.quote_post_id.isnull() & ~pairs.response_post_id.isnull()]\n",
        "\n",
        "triples = pairs.merge(\n",
        "    pairs, left_on=\"response\", right_on=\"quote\", how=\"inner\", suffixes=(\"_r1\", \"_r2\")\n",
        ")\n",
        "\n",
        "# Rename and reorder columns\n",
        "triples = triples.rename(\n",
        "    columns={\"quote_r1\": \"quote\", \"quote_r2\": \"response1\", \"response_r2\": \"response2\"}\n",
        ")\n",
        "triples = triples.drop(columns=[\"response_r1\"])\n",
        "front_columns = [\n",
        "    \"quote\",\n",
        "    \"response1\",\n",
        "    \"response2\",\n",
        "    \"attack_r1\",\n",
        "    \"fact-feeling_r1\",\n",
        "    \"nicenasty_r1\",\n",
        "    \"sarcasm_r1\",\n",
        "    \"agreement_r2\",\n",
        "]\n",
        "triples = triples.dropna(subset=front_columns)\n",
        "triples = triples[front_columns].join(triples.drop(columns=front_columns))\n",
        "triples.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "188c72c233a2697a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-21T04:54:45.418667Z",
          "start_time": "2024-02-21T04:54:45.403835Z"
        },
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:           agreement_r2   R-squared:                       0.013\n",
            "Model:                            OLS   Adj. R-squared:                  0.012\n",
            "Method:                 Least Squares   F-statistic:                     17.95\n",
            "Date:                Tue, 20 Feb 2024   Prob (F-statistic):           2.43e-05\n",
            "Time:                        22:54:45   Log-Likelihood:                -2572.2\n",
            "No. Observations:                1340   AIC:                             5148.\n",
            "Df Residuals:                    1338   BIC:                             5159.\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==========================================================================================\n",
            "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------------------\n",
            "const                     -1.4440      0.058    -24.736      0.000      -1.559      -1.330\n",
            "fact-feeling_unsure_r1     1.3837      0.327      4.236      0.000       0.743       2.024\n",
            "==============================================================================\n",
            "Omnibus:                       84.869   Durbin-Watson:                   1.851\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              100.554\n",
            "Skew:                           0.631   Prob(JB):                     1.46e-22\n",
            "Kurtosis:                       3.459   Cond. No.                         7.34\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ],
      "source": [
        "ex_y = triples[\"agreement_r2\"]\n",
        "ex_x_cols = [\"fact-feeling_unsure_r1\"]\n",
        "ex_x = sm.add_constant(triples[ex_x_cols])\n",
        "\n",
        "ex_lm = sm.OLS(ex_y, ex_x).fit()\n",
        "print(ex_lm.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e524ce946c130577",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "**Thoughts:** In the above OLS linear regression, I test whether the initial\n",
        "responder's lean toward a factual or feeling-based response has a causal effect \n",
        "on the second response's agreement measurement. Based on the data above, it has a\n",
        "significant effect (below a .001 level) on whether the second response agrees.\n",
        "Though it does have a significant effect, it does not account for much of the \n",
        "variation in `agreement_r2`, based on the Adjusted R-squared value (0.012), with the \n",
        "value of `fact-feeling_unsure_r1` only accounting for 1.2% of the variation \n",
        "in `agreement_r2`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45de25784b9ac5b7",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "## <font color=\"red\">*Exercise 3*</font>\n",
        "\n",
        "<font color=\"red\">Propose a measure you could generate to fill in or improve upon the simple causal model you proposed above and how you would split the data (e.g., a % of your main data, a separate-but-informative dataset). You do not have to produce the measure.\n",
        "    \n",
        "<font color=\"red\">***Stretch*** (not required): Produce the measure and integrate it into your statistical analysis. This could be a great approach for your final project!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f56e7268aac1f8b5",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "The recommendation in the example would be useful for here as well. Given that\n",
        "there a multitude of pairs that do not belong to the triples collection, I would\n",
        "use that split. I would test my model improvement, listed below, on the \n",
        "pairs split, and if successful, validate it on the triples.\n",
        "\n",
        "To improve the model, I would add a length component, `len(r1.split())`,\n",
        "for the first response in an attempt to validate the assumption that feeling\n",
        "statements are often shorter and curt, as opposed to factual statements that\n",
        "tend to be more verbose. My intuition is that this first response length measurement\n",
        "co-variable would help to improve the Adjusted R-squared so that more than 1.2%\n",
        "of the variation is accounted for within the model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0197942bf7ee36",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "## <font color=\"red\">*Exercise 4*</font>\n",
        "\n",
        "<font color=\"red\">Propose a mediation model related to the simple causal model you proposed above (ideally on the dataset you're using for your final project). If you have measures for each variable in the model, run the analysis: You can just copy the \"Mediation analysis\" cell above and replace with your variables. If you do not have measures, do not run the analysis, but be clear as to the effect(s) you would like to estimate and the research design you would use to test them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "346671c93ce01d1e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-02-13T20:54:55.935587Z",
          "start_time": "2024-02-13T20:54:55.929091Z"
        },
        "collapsed": false
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "8490fb2e34f5050c",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "## <font color=\"red\">*Exercise 5*</font>\n",
        "\n",
        "<font color=\"red\">Pick one other paper on causal inference with text from the [\"Papers about Causal Inference and Language\n",
        "\" GitHub repository](https://github.com/causaltext/causal-text-papers). Write at least three sentences summarizing the paper and its logic of design in your own words.\n",
        "    \n",
        "<font color=\"red\">***Stretch*** (not required): Skim a few more papers. The causal world is your textual oyster!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75350cb3f501605b",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "**Title:** A Survey of Online Hate Speech through the Causal Lens ([Link](https://arxiv.org/pdf/2109.08120.pdf))\n",
        "**Summary:** Using a causal lens, the paper looks into the historical academic basis, reasoning, and \n",
        "complications associated with studying online hate speech. Their particular focus is describing studies \n",
        "grouped into three specific causal fields: digital misbehaviors versus the physical world, harmful content\n",
        "versus the individual, and the effect of interventions on individuals. Lastly, the authors discuss the \n",
        "prevailing difficulties associated with the convergence of causal research methods and natural language \n",
        "processing (confounding bias, linguistic representations, and causal transportability) and provide \n",
        "suggestions for future researchers to successfully navigate the obstacles mentioned above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "228c86a24186c5da",
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
