{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cbf16f4c9ae2d96",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Constants, Utility Functions, and Data Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf30fc4eb9ca27ed",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3cd0e46fb80e4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecdd2a2e9f4fec",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data Importing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5549c3605b54cfa1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## <font color=\"red\">*Exercise 1*</font>\n",
    "\n",
    "<font color=\"red\">As this week's challenging questions asks, we'd like you to \n",
    "think how LLM can help your final project.  Try to use the OpenAI API to analyze \n",
    "a small-sized dataset (Remember to monitor API use on your OpenAI account!). The \n",
    "data could a sample from the dataset you prepare for the final project or some \n",
    "others. If it's going be a conventional task like classification, compare and \n",
    "see how it could beat(or being defeated) by other algorithms you've learned from \n",
    "previous weeks. If it's a special task that you cannot find a learned algorithm \n",
    "to compare with, evaluate its performance on your own and try if you can improve \n",
    "by changing hyperparameters(see [here](https://platform.openai.com/docs/api-reference/chat/create)), the prompt, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e5e3f3488f9262",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7aaec3f33a7e7f5c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## <font color=\"red\">*Exercise 2*</font>\n",
    "\n",
    "<font color=\"red\">Fine-tune an LLM. You can either use the model (llama-2-7b) in \n",
    "the example code or find another open-source LLM. You may use datasets provided \n",
    "by HuggingFace or a dataset you collect from somewhere else (for your final project). \n",
    "If the task happens to be the same as in exercise 1, You can choose to compare the \n",
    "performance between the OpenAI LLM and your fine-tuned LLM. You can also choose to \n",
    "compare the performance between the vanilla and the fine-tuned LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb555776de120e74",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f57769d2db2531e5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## <font color=\"red\">*Exercise 3*</font>\n",
    "<font color=\"red\">Use LLM to generate some data and compare the differences between model-generated \n",
    "data and actual data. This exercise should not be a repetition of exercise 1. You should \n",
    "focus more on analyzing language nuances, qualitatively or quantitatively. You should also \n",
    "notice how the choice of LLM has possibly impacted the language it uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d78775f496723b3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80a85d8d4b691f31",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## <font color=\"red\">*Exercise 4*</font>\n",
    "\n",
    "<font color=\"red\">Compare how LLMs change their performance with different \n",
    "shots on your task. If the evaluation criterion is quantifiable, such as \n",
    "classification with ground truth labels, plot and show how accuracy changes. \n",
    "If the evaluation criterion cannot be easily quantified, such as the clarity \n",
    "of explaining a concept, use your imagination to do some comparison (for \n",
    "example, you can ask another LLM to rate its peer :)) If you find close-sourced \n",
    "LLM APIs pricey and are unsatisfied with responses from small-sized open-sourced \n",
    "LLMs, you can try large-sized LLMs (such as 70B version Llama-2) with Petals \n",
    "(see [here](https://colab.research.google.com/drive/1uCphNY7gfAUkdDrTx21dZZwCOUDCMPw8?usp=sharing) and [here](https://colab.research.google.com/drive/1Ervk6HPNS6AYVr3xVdQnY5a-TjjmLCdQ))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6f9e4800dec460",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ee94a09c81beb4e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## <font color=\"red\">*Exercise 5*</font>\n",
    "\n",
    "<font color=\"red\">Using Actor - Critical method to improve an LLM's performance \n",
    "on your task or doing some experiments langauge style learning (For example, \n",
    "you can investigate how LLMs perceive different groups of people would write \n",
    "their dating profiles. This may serve as an opportunity to explore how LLMs \n",
    "semantically embed social groups and assess their appropriateness.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8c073f73ebb314",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
